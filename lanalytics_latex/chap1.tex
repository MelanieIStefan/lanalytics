\chapter{Introduction}

In the psychometrics and educational literature different ideas for the evaluation of students have been developed. The variety of ideas is diverse, from models that accurately measure the student knowledge and proficiency in a topic to models that help in the quiz and item design. Although the ideas for these models typically arise from social sciences questions and assumptions, they are backed by statistical and mathematical tools that help to measure and interpret the results. This way, with the collaboration from both fields, a more detailed assessment and interpretation of the results can be provided for the students and instructors.


One idea for student assessment is through high-stake and low-stake tests. The basic idea is to apply one or more tests with different frequency level with the purpose to evaluate the knowledge and proficiency of the student for a topic or a set of topics. The frequency of the tests plays an important role in this text, in special the low-stake high-frequency quizzes. Frequent quizzes allow monitoring the student performance during the course, permitting the instructor to take actions based on the obtained information. On the other hand, in the high-stake quizzes, the instructor can only assess the knowledge of the students at the end of the course or when the high stake test is taken.

In this dissertation, some difficulties in the analysis of the low-stake high-frequency tests will be covered. Because the number of tests and the generated information increases, the time to evaluate each item and test difficulty is reduced, so a tool to quickly calculate them is required. Additionally, a tool to manage and constantly analyse the answers from the students is required, both to assess the required time for each quiz and to measure the performance of the group and particular students. All of these having as an objective that the instructor could quickly respond to the needs of the students in the group \cite{payne2009information} \cite{moodle}.

For the first point, the estimation of the item difficulty parameter, the use of the Item Response Theory will be proposed, in special of the Rasch models. These models allow to calculate a difficulty parameter for each item and also to provide the student's ability parameter. The most interesting part of this model is that it makes comparable both sets of parameters. This information can potentially benefit the class instructors because they will have a tool to prepare the tests difficult according to the student's abilities. Furthermore, the instructors can perform Just in Time Teaching and adapt their tests difficulties and necessities according to the specific group requirements. Currently, these models are implemented in R packages \footnote{For example in the eRm and the ltm packages.}.

For the second point, the management and constant analysis of student answers and test times, a new package is proposed. The main objective of this package is to ease the test analysis and make it feasible for instructors. This package is called \textit{lanalytics}, and its main objective is to administer and analyse quizzes in different grouping levels: per person, per quiz and per group. To include the idea of quizzes administration, the package can create a quiz object and a course object. Then the instructors can export all the data from the quizzes as an R data file or *.csv file. Then, if further analysis is required, they simply have to read the data files to visualise it and make an analysis. The package includes different visualisation tools that work with these quiz and course objects.

To join this two ideas, the management and analysis of the test's information and the estimation of the item difficulty and student abilities, a user interface is proposed. This interface is named \textit{The lanalytics dashboard} and is implemented in Shiny R, that is completely free and open source. As it can be hosted on a web page, it can allow that users that are not familiar with R can have access to the lanalytics package and some functions of the eRm package. As building a comprehensive software that makes analyses data from a wide spectrum of sources is a very long task, this will be just a prototype for further future developments.

In the second chapter of this dissertation, the background for Just in Time Teaching (JiTT) and Item Response Theory (IRT) will be given. In specific, the Rasch models and the plots that will be used in the dashboard will be covered. Later, in the third chapter, the lanalytics package will be introduced, and the motivation for each of the generated plots will be explained. In the fourth chapter, the Shiny interface prototype will be presented, and each component will be explained. In the fifth chapter, a user experience evaluation of the Shiny interface will be documented. Finally, the conclusions and future work will be provided in the sixth chapter.

All this project is stored in Github. The URL of both the package and the dashboard is: \url{https://github.com/savrgg/lanalytics}